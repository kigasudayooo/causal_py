# 機械学習による因果推論について

## 目次
- [機械学習による因果推論について](#機械学習による因果推論について)
  - [目次](#目次)
  - [EconMLとは](#econmlとは)
    - [参考資料集](#参考資料集)
    - [Meta-Learners](#meta-learners)
      - [T-Learner](#t-learner)
      - [S-Learner](#s-learner)
      - [X-Learner](#x-learner)
      - [R-Learner(githubのページ)](#r-learnergithubのページ)
      - [その他の手法](#その他の手法)
    - [Meta-Leanerの利点](#meta-leanerの利点)
  - [Double/Debiased Machine Learningについて](#doubledebiased-machine-learningについて)
    - [参考資料](#参考資料)
      - [概要はここ](#概要はここ)
      - [一部抜粋](#一部抜粋)
        - [設定](#設定)
        - [Double/Debiased Machine Learning](#doubledebiased-machine-learning)
        - [ネイマン直交条件](#ネイマン直交条件)
        - [Cross-fitting](#cross-fitting)
        - [DMLの応用可能性と今後の展望](#dmlの応用可能性と今後の展望)
  - [Causal Forestについて](#causal-forestについて)
    - [参考資料](#参考資料-1)
      - [そもそもランダムフォレストとは](#そもそもランダムフォレストとは)
    - [モチベーション](#モチベーション)
    - [概要](#概要)
      - [PartitioningとTree推定量](#partitioningとtree推定量)
    - [諸々略](#諸々略)
    - [Generalized Random Forest](#generalized-random-forest)


## EconMLとは
- EconMLは、Microsoft Researchが開発した因果推論のためのPythonパッケージ
- Heterogeneous Treatment Effect Estimation(異質処置効果推定)を行うことができる


 ### 参考資料集
- [EconML](https://econml.azurewebsites.net/index.html)
- [EconMLのサンプルコード](https://github.com/py-why/EconML/tree/main/notebooks)
- [EconMLパッケージの紹介 (meta-learners編)](https://usaito.hatenablog.com/entry/2019/04/07/205756)
- [機械学習で因果推論~Meta-LearnerとEconML~](https://zenn.dev/s1ok69oo/articles/1eeebe75842a50)
- [CATEを推定するMeta-Learnersの特徴と比較](https://saltcooky.hatenablog.com/entry/2020/08/16/003950)
- [Uplift Modelingで介入効果を最適化する](https://qiita.com/usaito/items/af3fa59d0ee153a70350)
  * A/Bテスト (RCT)によって収集された学習データがあることを前提とする効果検証手法
- [めっさ分かりやすい因果推論](https://www.ariseanalytics.com/activities/report/20210409/)
- [異質な因果効果とその推定方法](https://qiita.com/ssugasawa/items/15ca8ae09477c5023c1e#x-learner)
- [BART: Bayesian additive regression treesによる因果推論](https://tmitani-tky.hatenablog.com/entry/2019/11/14/014056)



### Meta-Learners
- EconMLにおける異質処置効果推定の手法

#### T-Learner
- 処置群の結果を予測するモデルと非処置群の結果を予測するモデルの2つのモデルを用意する
$$
\hat{\tau}(x) = \hat{\mu}_{1}(x) - \hat{\mu}_{0}(x) 
$$
ここで、$\hat{\mu}_{0} = E[Y^{(0)} | X = x]$,$\hat{\mu}_{1} = E[Y^{(1)} | X= x]$となっている。つまり、対照群と処置群のそれぞれについて、関心のある共変量Xの下での反応の推定を行い、その結果を比較する。

- T-learnerでは処理群と対照群の観測データをプールして利用していないため、処理群と対照群のそれぞれのデータ生成過程の違いが推定性能に影響を与える。
- 処理群と対照群のそれぞれのデータ生成過程が等しい場合は、不利になる傾向になる。
- 他方で、処置効果の構造が非常に複雑で、処理群と対照群のそれぞれのデータ生成過程に共通の傾向がない場合には、特に優れた性能を発揮する傾向にある。

#### S-Learner
- 処置群の結果を予測するモデルと非処置群の結果を予測するモデルの2つのモデルを用意する
$$
\hat{\tau}(x) = \hat{\mu}(x,1) - \hat{\mu}(x,0) 
$$
ここで、$\mu(x,w) := E[Y^{obs}|X = x, W = w]$となっている。つまり、推定したモデルの対象に対して、wに0/1を代入した差分を考える。
- S-learnerでは、処置変数を他の共変量の同様に扱い、処置変数には特別な役割はない。
- そのため、lassoやRandomForestのようなアルゴリズムは、治療の割り当てを完全に無視して、治療の割り当てを選択しないこともできる。
- シミュレーション結果から、データ生成過程が等しい場合とCATEが多くの場所で0である場合において、最も良い推定を行うことが確認できる。


#### X-Learner
- まず、T-learner同様に$\hat{\mu}_{0} = E[Y^{(0)} | X = x]$,$\hat{\mu}_{1} = E[Y^{(1)} | X= x]$を考える。次に、$\hat{\mu}_{0}$を用いて、処置群の個人の処置を行わない場合の結果の推定を行う。この推定値と、観測された対照における結果の差を、個人の介入効果とする（$\tilde D^{0}_{i}$）。同様に処置群の効果も推定する。

$$
\tilde D^{1}_{i} := Y^{1}_{i} - \hat{\mu}_{0}(X^{1}_{i}) \\
\tilde D^{0}_{i} := Y^{1}_{i} - \hat{\mu}_{0}(X^{1}_{i})
$$

- そして介入群のみからなるデータと、対照群からなるデータそれぞれを用いて、介入効果を推定するモデルを作成する（二段階目のベース学習器）。

$$
\hat{\tau}_{0} = E[\tilde D^{0}_{i}  | X = x]\\
\hat{\tau}_{1} = E[\tilde D^{1}_{i}  | X= x]
$$

- 最後に、得られたベース学習器について、傾向スコア($g(x)$)を用いた重み付き平均を求めることで、介入効果を推定する。
$$
\hat{\tau}_{X}(x) = g(x)\hat{\tau}_{0}(x) + (1-g(x))\hat{\tau}_{1}(x)
$$

- X-learnerは，CATEに構造的な仮定がある場合や，一方の処置群が他方の処置群よりもはるかに大きい場合に特に優れた性能を発揮する。
- 期待されるCATEがほとんど0であるという強い信念がない限り、小さなデータサイズの場合はBARTを用いたX-learnerを、大きなデータサイズの場合にはRandomForestを用いるべきであるとしている。


#### R-Learner([githubのページ](https://github.com/xnie/rlearner))
- [Nie and Wager (2021)](https://arxiv.org/abs/1712.04912)によって提案された方法
- HTEを推定するために、ロビンソン分解（[Robinson (1988)](https://www.jstor.org/stable/1912705)）を用いる
  * [Kaddour et al.(2021)](https://arxiv.org/abs/2106.01939)もまた参考文献としてありそう。
$$
Y_i - m(X_i) = (T_i - g(X_i)) \tau(X_i) + \varepsilon_i
$$
ここで$m(X_i) = E[Y_i|X_i]$はアウトカムの条件付き期待値で、$g(X_i)$は傾向スコア。
これらの$m(X_i)$及び$g(X_i)$を用いて、R-learnerは以下の式を最小化するときの$X_i$を用い、介入効果($\tau(X_i)$)を推定する。なお、$\varLambda_n(\tau(\cdot))$は正則化項。
$$
\sum_{i=1}^{n} [(Y_i - m(X_i)) - (T_i - \pi(X_i)) \tau(X_i)]^2 + \varLambda_n(\tau(\cdot)) \\
$$
- 実務上は$m(X_i)$及び$g(X_i)$は道なので、観測データから推計する。手法を提案した研究では、$m(X_i)$及び$g(X_i)$の推定と$\tau(X_i)$の推定は、それぞれ元のデータセットを分割した、別々のデータセットを用いて行うことを提案している(cross-fitting)。

#### その他の手法
- DA-Learner (Domain Adaptation Learner)
  * DA-Learnerは, X-Learnerにおける$μ^0$,$μ^1$の学習に共変量シフトを用いた手法
- DR-Learner (Doubly Robust Learner)
  *  Doubly Robustを用いてCATEを代替するようなsurrogate outcomeを作り, それをXに回帰する方法
- [Targeted Maximum Likelihood Estimation:TMLEについて](https://saltcooky.hatenablog.com/entry/TLME22)
  * なんじゃこりゃ。super learnerとかいうのもあるらしい。


### Meta-Leanerの利点
- 特定のベース学習器に依存しない
  * 線形モデルではなくても良いことが利点。
  * 他方で、ベース学習器の選択をどのように行うかが重要となる。
  * 以下のような特徴がある、らしい。。。
    - データの生成構造が大域的に線形である状況やデータセットが小さい場合には、[(Bayesian Additive Regression Trees, BART)](https://tmitani-tky.hatenablog.com/entry/2019/11/14/014056)のように大域的に作用する推定器が大きな優位性を持つ。
      * $Y = \sum_{i=1}^{m} g(x:T,M) + \varepsilon, \varepsilon ∼
N(0,ρ)$というm個の木による加法的予測モデル（これを森と呼ぶ）をベイズで求めることを考える。初期値は適当なpriorを考え、森を作成したのちに木を一つずつMCMCで更新していく。
      * これが収束したら、事後分布に基づいたK個の森をサンプリングして、予測する際はK個の森を使うことで予測値の事後分布を得る。
      * 基本的には因果推論として特別なことをするわけではなく，treatmentも他のcovariateと同列に扱った予測モデルを構築し，その上でtreatment Z={0,1}とした予測値の差で因果効果を推定するアプローチ
      * authorのHillは，事前の知識や因果構造についての推論などをモデル化に活用すると，予測していなかった重要な結果をマスクしてしまったり，推定にバイアスを生んでしまう，という立場を取っている．なので事前知識に応じた既知の因果構造を取り込んだpriorを設定するといった方法論の記載は論文内にない．
    - 大域的な構造がない場合やデータセットが大きい場合には、Random Forestのような高次元の交互作用を用いることができるモデルが有利になる。
      * 結局これまでやってきたような介入効果は、簡単な構造でより効率的に（バリアンスにつ強い）推計をできる一方で、より複雑なデータの生成過程がある場合は、今回のようなより複雑なモデルを用いる必要があるということ？
      * 線形回帰モデルのあてはめは構造がシンプルすぎるのが問題ということらしい。概念としてはS-learnerが線形回帰モデルによる因果推論を内包していると考えられる？

![シミュレーションの設定](https://cdn-ak.f.st-hatena.com/images/fotolife/s/saltcooky/20200815/20200815162631.png)
![シミュレーションの結果](https://cdn-ak.f.st-hatena.com/images/fotolife/s/saltcooky/20200815/20200815011615.png)

## Double/Debiased Machine Learningについて

### 参考資料
- [Double/Debiased Machine Learning for Treatment and Structural Parameters](https://arxiv.org/abs/1608.00060)

#### [概要はここ](../docs/dml_nippyo.md)

#### 一部抜粋
##### 設定
あるモデルの推定したいパラメータ$\theta_0$が、モーメント条件
$$E[\psi(W;\theta_0,\eta_0)]=0$$

を満たすとする。ここで$W$は確率変数ベクトル、$\psi$はスコア関数と呼ばれる、既知の関数である。$\eta_0$は未知の関数である。関数$\eta_0$は線形などのパラメトリックな形を仮定されておらず、分析者の興味の対象ではないパラメータである。。このモデルのように、推定したいパラメータが有限次元であるが、興味の対象でない関数パラメータを含むモデルはセミパラメトリック・モデルと呼ばれ、政策効果・処置効果の推定、産業組織論や労働経済学における構造モデルの推定等で使われている。

例として、以下の部分線形モデルと呼ばれるセミパラメトリック・モデルを考えよう。
$$
Y = D\theta_0 + g_0(X) + U, E[U|X,D]=0
$$
ここで、$Y$はアウトカム、$D$は処置、$X$は共変量、$U$は観察できないノイズである。$g_0$は未知の関数である。このモデルでは、処置の効果$\theta_0$を推定したいが、関数$g_0$は興味の対象ではない。このモデルにおいて、モーメント条件を満たすスコア関数$\psi$は、複数存在する。たとえば、$W = (Y,X,D),\psi_1(W;\theta,g)=(Y-D\theta-g(X))D$とすると、真のパラメータ$(\theta_0,g_0)$において、モーメント条件$E[\psi_1(W;\theta_0,\eta_0)]=0$を満たす。また、$m_0(X)=E[D|X]$と定義し、$\psi_2(W;\theta,\eta)=(Y-D\theta-g(X))(D-m_0(X))$とすると、真のパラメータ$(\theta_0,\eta_0)$において、モーメント条件$E[\psi_2(W;\theta_0,\eta_0)]=0$を満たす。このように、モーメント条件を満たすスコア関数は複数存在する。

##### Double/Debiased Machine Learning
サイズ$N$のデータセット$\{W_i\}_{i=1}^N$が与えられたとする。このデータセットから、パラメータ$\theta_0$を推定するための手順を考える。通常、$\theta_0$を推定するためには、まず未知の関数$\eta_0$を推定する必要がある。関数の推定の古典的な手法として、カーネル回帰やシリーズ推定が知られるが、関数の引数が高次元である場合は、関数の推定を予測タスクに置き換え、機械学習を用いて推定するという方法が新たに提案されている。たとえば、上記の部分線形モデルにおける$m_0$の推定は、$D$を$X$で予測するタスクとみなせるため、LASSOやランダムフォレスト等を用いて行うことが可能である[^1]。機械学習を用いた推定は、とりわけ関数の引数が高次元の場合、推定誤差や収束レートの面で優れていることが理論的・実証的に示されている。データサイズと比して膨大な数の変数がある場合や、関数の引数にどの変数を入れるべきかわからない場合は、機械学習を用いることが妥当であろう。Chernozhukov et al. (2018a)は、機械学習を用いた$θ_0$の推定方法として、Double/Debiased Machine Learning(以下、DML)と呼ばれる以下の方法を提案し、その統計的性質を示した[^2]。

1. 無作為にデータセット$\{W_i\}_{i=1}^N$をサイズ$n = N/2$の２つのサンプル$\{W_i\}_{i\in I_1}$と$\{W_i\}_{i\in I_2}$に分割する。
2. ２つめのサンプル$\{W_i\}_{i\in I_2}$を使い、機械学習を用いて$\eta_0$の推定量$\hat\eta_{0,1}$を得る。次に、１つめのサンプル$\{W_i\}_{i\in I_1}$を使い、機械学習を用い、$\frac{1}{n}\sum_{i\in I_1} \psi(W_i;\theta,\hat\eta_{0,1})=0$を$\theta$について解き、推定量$\hat\theta_{0,1}$を得る。ただし、$\psi$はモーメント条件に加えて、後述するネイマン直行条件を満たすスコア関数である。
   - 補足として、スコア$\psi$をナイーブに機械学習手法を適用して推定すると、$\sqrt{N}-consistency$を持たないらしい。これは、傾向スコアにノンゼロな方向微分（[ガトー微分](https://mathwords.net/hankansu)というらしい）を持つためで、傾向スコアに対して、推定したスコア関数が変動してしまうことと、機械学習特有のペナルティ項の存在による収束レートの遅さ（ドンスカー条件）によるそうな…（[ソース](https://speakerdeck.com/masakat0/dmlniyoruchai-fen-falsechai-tui-ding?slide=20)）。
3. ステップ2を、2つのサンプルを入れ替えて行い、推定量$\hat\theta_{0,2}$を得る。
4. 最終的な推定量を$\hat\theta_0 = \frac{1}{2}(\hat\theta_{0,1}+\hat\theta_{0,2})$とする。

ここで、ステップ2および3において$\eta_0$の推定のためにどのような機械学習アルゴリズムを使うのかについての指定はなく、その選択は分析者に委ねられる。$\eta_0$の推定量の収束レートなどに関する条件が満たされる限り、使用するアルゴリズムによらず、DML推定量$\hat\theta_0$は$\frac{1}{\sqrt N}$のレートで$\theta_0$に収束し、漸近的に正規分布にしたがう。
これらの統計的性質を得るための鍵となるのが、①ネイマン直交条件を満たすスコア$\psi$を用いること、②cross-fittingを用いることである。この2つについてそれぞれ説明する。

##### ネイマン直交条件
機械学習アルゴリズムは、予測モデルがデータに過剰にフィットすることを防ぐため、正則化と呼ばれる、モデルの複雑さに制約を加える処理を行う。これにより、$\eta_0$の推定量の分散が小さく抑えられる一方で、その代償としてバイアスが大きくなる。そのバイアスは、モーメント条件を通じて、$\hat\theta_0$に影響を与える。以下で与えられるネイマン直交条件は、その影響の程度が軽減されるための条件である[^3]。
$$
\frac{\partial E[\psi(W;\theta_0 ,\eta_0 + r(\eta - \eta_0))]}{\partial r}\bigg|_{r_0} = 0
$$
左辺は関数$\eta_0$を$\eta-\eta_0$の方向に微笑に動かしたときの$E[\psi(W;\theta_0 ,\eta_0)]$の変動を表す。この変動がゼロであるということは、モーメント条件が$\eta_0$の推定誤差に対して頑健であることを意味する。その結果。バイアスのある$\eta_0$の推定量を用いたとしても、$\hat\theta_0$への影響が抑えられる。
部分線形モデルの例を挙げた際、モーメント条件を満たす2つのスコア$(\psi_1と\psi_2)$を紹介したが、簡単な計算により、スコア$\psi_1$は直行条件を満たさない一方、スコア$\psi_2$は直行条件を満たすことが示される。したがって、前者のスコアを用いた推定量の方が、$\eta_0$の推定のバイアスの影響を受けやすいと考えられる。[@fig:sim]ははこの2つのスコアを用いた推定量をシミュレーションにより比較したもので、ヒストグラムはシミュレーションで得られた$\hat\theta_0-\theta_0$の分布を表している。$\psi_1$を用いた推定量は、$\psi_2$を用いた推定量に比べて、バイアスが大きくなっていることがわかる。
![２つのスコアシミュレーション結果[^fig]](https://www.web-nippyo.jp/wp-content/uploads/2019/05/1.jpg){#fig:sim}

##### Cross-fitting
DMLのもう1つの特徴は、データ分割を行い、$\eta_0$の推定と$\theta_0$の推定を別々のサンプルで行うことである。データ全体を用いて$\eta_0$と$\theta_0$の両方を推定した場合、過学習によるバイアスが生じる（[@fig:sim2]）。一方で、データ分割を行うと、$\eta_0$の推定量が$\theta_0$の推定に用いるサンプルと独立になるため、バイアスを軽減することができる。理論的には、データ分割を行うことで、しばしばデータ分割を行わない場合より緩い条件の下で、推定量の$\frac{1}{\sqrt n}$の収束レートや漸近正規性を示せることがわかっている。

![２つのスコアシミュレーション結果2[^fig]](https://www.web-nippyo.jp/wp-content/uploads/2019/05/2.jpg){#fig:sim2}

また、DMLでは、ステップ２で$\theta_0$の推定量$\hat\theta_{0,1}$を得た後、２つのサンプルを入れ替えて$\theta_0$の２つめの推定量$\hat\theta_{0,2}$を求め、その二つの平均を最終的な推定量としている(cross-fitting)。これは、データすべてを使うため効率性を損なわずにバイアスを取り除くことが可能になる。

##### DMLの応用可能性と今後の展望
本稿で紹介したDMLは、セミパラメトリック・モデルの関数パラメータ$(\eta_0)$が高次元な場合においても、関心のあるパラメータ$(\theta_0)$をバイアスの小さい形で推定することを可能にする。代表的な応用例は、部分線形モデルの推定や、平均処置効果等の処置効果の推定であり、因果推論やプログラム評価において、多数の共変量を適切にコントロールするためにDMLを適用する実証研究が登場してきた。一方、その他のモデルにDMLを応用するには、直交条件を満たすスコア$\psi$をみつけることが必要である。たとえば、本稿で紹介したものとは別の研究であるChernozhukov et al. (2018b)はスコアの構築方法を提示しており、例として動学的離散選択モデルの推定のためのスコアを導出している。今後は、処置効果の推定だけでなく、産業組織論や労働経済学等の分野における構造モデルの推定にもDMLが応用されることが考えられる。


## Causal Forestについて

### 参考資料
- [ランダムフォレストによる因果推論と最近の展開](https://speakerdeck.com/tomoshige_n/randamuhuoresutoniyoruyin-guo-tui-lun-tozui-jin-nozhan-kai-838c3989-570d-49ca-b630-22044a798589)

#### そもそもランダムフォレストとは 
- ランダムフォレストは, パラメータの識別ではなく, 変数$x$に対して目的変数$y$の予測値$\hat y$を求めるためのアルゴリズムである. よって, 予測値$\hat y$がどれだけ$y$を正確に予測するかが課題であり, パラメータをバイアスなく推定するといったことは必ずしも要求されない. これはランダムフォレストに限らず, 機械学習全般に当てはまる.([source](https://ill-identified.hatenablog.com/entry/2018/08/02/004625))

- [wiki](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E3%83%95%E3%82%A9%E3%83%AC%E3%82%B9%E3%83%88)
- アルゴリズム
  * 学習
    1. 学習を行いたい観測データから、ブートストラップ法によるランダムサンプリングにより B 組のサブサンプルを生成する
    2. 各サブサンプルをトレーニングデータとし、B 本の決定木を作成する
    3. 指定したノード数 $n_{min}$に達するまで、以下の方法でノードを作成する
         1. トレーニングデータの説明変数のうち、m 個をランダムに選択する
         2. 選ばれた説明変数のうち、トレーニングデータを最も良く分類するものとそのときの閾値を用いて、ノードのスプリット関数を決定する
  * 評価
    - **識別**: 決定木の出力がクラスの場合はその多数決、確率分布の場合はその平均値が最大となるクラス
    - **回帰**: 決定木の出力の平均値
  * 要点は、ランダムサンプリングされたトレーニングデータとランダムに選択された説明変数を用いることにより、相関の低い決定木群を作成すること。 
-  長所
   * 説明変数が多数であってもうまく働く
   * 学習・評価が高速
   * 決定木の学習は完全に独立しており、並列に処理可能
   * 説明変数の重要度（寄与度）を算出可能
   * Out of Bag エラーの計算により、クロスバリデーションのような評価が可能
   * AdaBoost などと比べて特定の説明変数への依存が少ないため、クエリデータの説明変数が欠損していても良い出力を与える
- 短所
   * 説明変数のうち意味のある変数がノイズ変数よりも極端に少ない場合にはうまく働かない

### モチベーション
HTEの推定は、例えば個人に対する因果効果を、興味のある変数のみに絞った回帰モデルによって周辺化 (marginalization) することにより推定することができる。
$$
argmin \sum_{i\in N} {((\frac{A_i}{\pi(X_i)} - \frac{1-A_i}{1-\pi(X_i)})Y_i - \mu(X_i;\beta))}^2
$$
- 従来の傾向スコア$\pi(X)$の逆数による重みづけは、傾向スコアをパラメトリックに推定する手法であり、モデルの誤特定の問題がある。
- ノンパラメトリックな推定を行った結果を、推定量に代入すると 漸近正規性の前提となる仮定が崩れるので、直接用いたくはない。 
- 傾向スコアを推定する理由がない限りは、$\pi : \mathcal{X} \mapsto (0, 1) $の経由を避け る方が良く、これは ATE であっても、HTE であっても同じである。 
-  これらの問題に対して、causal tree, causal forest, generalized random forest は新たな推定方法として注目されている。

### 概要
- Causal Trees (Athey and Imbens, 2016) はrecursive partitioning を用いて、Heterogeneous causal effectを推定する手法である。
- この論文においては、causal treeの他に重要なtreeにおける考え方**honest**が提案されており、これがcausal forestやGRFの漸近正規性の証明において中心的な枠割を果たす。
  * honest 性とは Tree の当てはめにおいて「Partitioningを生成するために用いるサンプル」と「Tree の Leaf 毎の 推定量の計算に用いるサンプル」に別のものを用いることで、2 つが独立になった Tree のこと
- また、honest性を満たすtreeは従来の(classification and regression tree , CART)と比較して過学習を起こしにくいという性質もある

#### PartitioningとTree推定量

特徴空間$\mathcal{X}$を背反に分割するpartiotioningを
$$
\mathcal{\Pi} = \{\ell_1,\ell_2,...,\ell_{\#(\Pi)}\}
$$
ただし
$$
\cup _{j=1}^{\#(\Pi)}\ell_j = \mathcal{X} \ and \ \ell_j \subset \mathcal{X}
$$
で定義する。この時、partitioning $\Pi$ が与えられた下での、条件付き平均関数$\mu(x;\Pi)$を
$$
\mu(x;\Pi) = E[Y_i|X_i \in \ell(X;\Pi)] \ = E[\mu(x_i)|X_i \in \ell(X;\Pi)]
$$
さらに、サンプル$\mathcal{S}$のデータを用いて構成したTree推定量$\hat\mu(X,S;\Pi)$を、
$$
\hat\mu(X,S;\Pi)=\frac{1}{\# \{i \in S:X_i \in \ell(X;\Pi)\}} \sum_{\{i \in S:X_i \in \ell(X;\Pi)\}} Y_i
$$
で定義する。ただし、$\ell(X;\Pi) \in \Pi$はXを含むpartitioning$\Pi$の元である。

- 要するに、推定量のペアの集合をそれぞれ、$\ell_i$に分割して、そのサブセットの中で推定量$\hat\mu$を計算するという考え方。
- honest性は、この分割に用いるデータと、分割に基づいて$\hat\mu$を推定するデータは独立となる性質のこと。
  * 特にCATEをどのように求めるのかはそのサンプルサイズに依存しそう
  * 従来のCARTとは異なり、Honest性を持つ推定量は、分割の数と、それぞれの分割内の分散によって定まるペナルティ項があるため、これがある意味でCATEの導出における制約になっている。
- 元々の割付が属性に対してある程度ランダムかつ中～大規模な介入でなければ、効率的な推定量が得られなさそう。この点は、DMLのほうが良い点かも。

- honest性を持つcausal tree の当てはめは、**(i) Leaf 間での処置効果の差の最大化**、および **(ii) 分割によって上昇する処置群と対照群の結果変数の分散の最小化**、の2つのトレードオフの最適化となる。 
- 因果効果は 2 つの潜在結果変数の差として定義される。そのため因果効果の異質性が分割によって上昇することと、leaf 間の処置群と対照群の分散が小さくなることは、regression の場合のように比例関係があるわけではない。 
- 罰則の意味が、regression の場合と causal inference では異なってくる点に注意が必要である。

### 諸々略

### Generalized Random Forest
まとめると[「個別効果の異質性 (heterogeneity) のある因果推論モデルのパラメータ (異質的処置効果: Heterogeneous Treatment Effect) を推定するために, モデルの誤差を基準にした Ramdom Forest で個体をクラスタリングし, 得られた推定クラスタをもとに一般化モーメント法 (GMM) を 局所回帰してパラメータを識別するアルゴリズム」](https://ill-identified.hatenablog.com/entry/2018/08/02/004625)のこと。